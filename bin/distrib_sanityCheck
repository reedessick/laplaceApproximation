#!/usr/bin/python

__usage__ = 'distrib_sanityCheck [--options] key,value key,value key,value ...'
__description__ = "written to make sure the posteriors for lnBSN and lnBCI follow the expected trends as we inject a population of signals. Key value pairs are passed to laplaceApprox.utils.sample_rhoA2orhoB2o after values are cast to floats"
__author__ = "Reed Essick (reed.essick@ligo.org)"

#-------------------------------------------------

import os
import numpy as np

from laplaceApprox import utils

import matplotlib
matplotlib.use('Agg')
from matplotlib import pyplot as plt

from optparse import OptionParser

#-------------------------------------------------

parser = OptionParser(usage=__usage__, description=__description__)

### verbosity and output

parser.add_option('-v', '--verbose', default=False, action='store_true')
parser.add_option('-V', '--Verbose', default=False, action='store_true')

parser.add_option('', '--colormap', default='OrRd', type='string')
parser.add_option('', '--contour-color', default='w', type='string')
parser.add_option('', '--overlay-color', default='k', type='string',
    help='the color used to plot the expected scalings')

parser.add_option('', '--log', default=False, action='store_true')

parser.add_option('', '--force-normalization', default=False, action='store_true',
    help='force the distribution to be normalized over the plotting range alone')

parser.add_option('', '--figwidth', default=6, type='float')
parser.add_option('', '--figheight', default=5, type='float')

parser.add_option('-o', '--output-dir', default='.', type='string')
parser.add_option('-t', '--tag', default='', type='string')

### parameters for scaling relation

parser.add_option('', '--c_bsn', default=1.0, type='float',
    help='passed to BayesMapParams')
parser.add_option('', '--g_bsn', default=1.0, type='float',
    help='passed to BayesMapParams')
parser.add_option('', '--c_bci', default=1.0, type='float',
    help='passed to BayesMapParams')
parser.add_option('', '--g_bci', default=1.0, type='float',
    help='passed to BayesMapParams')

parser.add_option('', '--f_tol', default=1e-10, type='float',
    help='numerical precision used when converting lnBSN -> rho2')

### marginalization

parser.add_option('', '--frac', default=0.01, type='float',
    help='used to determine how the sampling uncertainty scales with the injected value')
parser.add_option('', '--tukey-alpha', default=0.1, type='float',
    help='the Tukey window\'s alpha paramter used when computing the FFT \
to spectrallyconvolve lnProb with sampling errors')

### distribution

parser.add_option('', '--Ngrid', default=100, type='int', 
    help='number of grid samples per side in the (lnBSN, lnBCI) grid')
parser.add_option('', '--Nsamp', default=100, type='int',
    help='number of "samples" to draw from distribution of (rho2Ao, rho2Bo)')

parser.add_option('', '--distrib', default='uniform', type='string',
    help='the type of distribution used to sample (rho2Ao, rho2Bo). Must be one of : %s'%(', '.join(utils.known)))

parser.add_option('', '--min-lnBSN', default=5, type='float',
    help='mimimum used to determine grid')
parser.add_option('', '--max-lnBSN', default=50, type='float',
    help='maximum used to determine grid')

parser.add_option('', '--min-lnBCI', default=5, type='float',
    help='mimimum used to determine grid')
parser.add_option('', '--max-lnBCI', default=50, type='float',
    help='maximum used to determine grid')

opts, args = parser.parse_args()

if opts.tag:
    opts.tag = "_"+opts.tag

if not os.path.exists(opts.output_dir):
    os.makedirs(opts.output_dir)

opts.verbose = opts.verbose or opts.Verbose

### set up kwargs for utils.sample_rhoA2orhoB2o
kwargs = dict((key,float(value)) for key, value in [arg.split(',') for arg in args])

#-------------------------------------------------

if opts.verbose:
    print( "setting up sample grid" )

### set up scaling relation
params = utils.BayesMapParams(c_bsn=opts.c_bsn, g_bsn=opts.g_bsn, c_bci=opts.c_bci, g_bci=opts.g_bci)

### determine grid
lnbsn, lnbci = np.meshgrid( np.linspace(opts.min_lnBSN, opts.max_lnBSN, opts.Ngrid), np.linspace(opts.min_lnBCI, opts.max_lnBCI, opts.Ngrid) )
lnBSN = lnbsn.flatten()
lnBCI = lnbci.flatten()

lnProb = -np.infty*np.ones(opts.Ngrid**2, dtype=float)
marg_lnProb = -np.infty*np.ones(opts.Ngrid**2, dtype=float)

#------------------------

if opts.verbose:
    print( "sampling from --distrib=%s"%opts.distrib )

samples = utils.sample_rhoA2orhoB2o( opts.Nsamp, distrib=opts.distrib, **kwargs )

for ind, (rhoA2o, rhoB2o) in enumerate(zip(*samples)):
    if opts.Verbose:
        print( "  %d / %d"%(ind+1, opts.Nsamp) )
        print( "    rhoA2o : %.3e"%rhoA2o )
        print( "    rhoB2o : %.3e"%rhoB2o )
        print( "    computing dprob" )

    ### compute the probability along the grid and add it to the existing distribution
    dprob = utils.lnProb_lnBSNlnBCI_given_rhoA2orhoB2o(
        lnBSN,
        lnBCI,
        rhoA2o*np.ones_like(lnBSN, dtype=float),
        rhoB2o*np.ones_like(lnBSN, dtype=float),
        params,
        f_tol=opts.f_tol,
    )
    dprob[dprob!=dprob] = -np.infty ### get rid of any nan's
                                    ### FIXME we may want to be smarter about this and 
                                    ### prevent nans from showing up in the first place

    # add this to un-marginalized posterior
    lnProb = utils.sumLogs(np.array([lnProb, dprob]), axis=0)

    # marginalize over sampling errors
    if opts.Verbose:
        print( "    marginalizing over sampling errors" )
    dprob = utils.convolve_samplingErrors(
        lnbsn, ### need to use these because we want 2D shape
        lnbci, 
        dprob.reshape((opts.Ngrid,opts.Ngrid)), ### need to reshape to apply 2D FFT 
        rhoA2o, 
        rhoB2o, 
        params, 
        frac=opts.frac, 
        tukey_alpha=opts.tukey_alpha,
    ).flatten() ### flatten this to get the correct shape
    # add to marginalized posterior
    marg_lnProb = utils.sumLogs(np.array([marg_lnProb, dprob]), axis=0)

if opts.force_normalization:
    lnProb -= utils.sumLogs(lnProb)
    marg_lnProb -= utils.sumLogs(marg_lnProb)

else:
    lnProb -= np.log(opts.Nsamp) ### normalize
    marg_lnProb -= np.log(opts.Nsamp)

lnProb = lnProb.reshape((opts.Ngrid,opts.Ngrid)) ### reshape to a raster of pixels
marg_lnProb = marg_lnProb.reshape((opts.Ngrid,opts.Ngrid))

print( "WARNING: need to write posterior to disk in a recoverable way" )

#------------------------

if opts.verbose:
    print( "plotting lnProb(lnBSN, lnBCI)" )

extent = [np.min(lnBSN), np.max(lnBSN), np.min(lnBCI), np.max(lnBCI)]

for z, label, tag, in [(lnProb,      'p(\ln B^S_N,\ln B^C_I|\Delta=\Delta^\prime=0)', 'mode'), \
                       (marg_lnProb, 'p(\ln B^S_N,\ln B^C_I)',                        'marg')]:
    fig = plt.figure(figsize=(opts.figwidth, opts.figheight))
    ax = fig.gca()

    if not opts.log:
        z = np.exp(z) ### convert out of log for plotting
        colorbar_label = '$'+label+'$'

    else:
        colorbar_label = '$\ln\,'+label+'$'

    z = z.real ### this should not be necessary...

    imag = ax.imshow(
        z, 
        interpolation='bilinear', 
        origin='lower', 
        extent=extent, 
        aspect='auto', 
        cmap=opts.colormap,
    )
    contours = ax.contour(
        z, 
        interpoloation='bilinear', 
        origin='lower', 
        extent=extent, 
        colors=opts.contour_color,
    )

    colorbar = plt.colorbar(imag, orientation='vertical')

    ax.set_xlabel('$\ln B^S_N$')
    ax.set_ylabel('$\ln B^C_I$')

    colorbar.set_label(colorbar_label)

    print( "WARNING: need to overlay expected scaling with rho2 at various values of eta2OVERrho2. Use --overlay-color" )

    figname = "%s/distrib_%s-%s%s.png"%(opts.output_dir, tag, opts.distrib, opts.tag)
    if opts.verbose:
        print( "    saving : %s"%figname )
    fig.savefig( figname )
    plt.close(fig)


